#chapter4 深层神经网络  
##4.1 深度学习与深层神经网络  
深度学习：一定通过多层非线性变换对高度复杂性数据建模算法的合集。  
深度神经网络是实现“多层非线性变换”的常用方法，所以实际中，深度学习就是深层神经网络的代名词  
深度学习两个特性： 多层，非线性
###4.1.1 线性模型的局限性
    线性模型：
    线性代数，以及向前传播计算公式，矩阵的乘法……    
    只通过线性变换，任意层全连接神经网络和单层神经网络模型表达能力没有差别（矩阵乘法），这就是线性模型最大的局限性，所以深度学习强调非线性！
    在线性可分问题中，线性模型就能很好区分不同颜色的点。因为线性模型就能解决线性可分问题，所以在深度学习的定义中特意强调它的目的为解决更 加复杂的问题。 所谓复杂问题，至少是无法通过直线（或者高维空间的平面）划分的    
###4.1.2激活函数实现去线性化
激活函数是如何工作
神经元结构的输出为所有输入的加 权和，这导致整个神经网络是一个线性模型。
如果将每一个神经元（也就是神经网络中的 节点）的输出通过一个非线性函数，那么整个神经网络的模型也就不再是线性的了.这个非线性函数就是激活函数
加入激活函数和偏置项之后
中增加了 偏置项（bias），偏置项是神经网络中非常常用的一种结构。 第二个改变就是每个节点的取 值不再是单纯的加权和。 每个节点的输出在加权和的基础上还做了一个非线性变换。 

###4.1.3 多层网络解决异或运
解深度学习的另外一个重要性质一一多层变换
一个能够模拟异或运算的数据集
##4.2 损失函数定义
神经网络模型的效果以及 优化的目标是通过损失函数（ loss function）来定义
###4.2.1 经典损失函数
分类问题和回归问题是监督学习的两大种类
分类问题希望解决的是将不同的样本分到事先定义好的类别中
个零件是否合格的问题就是一个二分类问题。
手写体数字识别问题可以被归纳成一个十分类问题。
虽然设置多个阔值在理论上是可能的，但在解决实际问题 的过程中一般不会这么处理。 
络解决多分类问题最常用的方法是设置 n 个输出节点，其中 n 为类别的个 数
判断一个输出 向量和期望的向盘有多接近呢？交叉蛐（cross entropy）是常用的评判方法之一。交叉：脑刻 画了两个概率分布之间的距离， 它是分类问题中使用 比较广的一种损失函数。 
交叉姻是一个信息论中的概念，它原本是用来估算平均编码长度的
两个概率分布p 和 q， 通过 q 来表示p 的交叉煽为H(p,q),两个概率分布之间的距离
利用Softmax回归将神经网络向前传播得到的结果也变成概率分布。Softmax回归可以作为一个学习算法来优化分类结果，，但在 TensorFlow 中， s。如nax 回归的参数被去掉了，它只是一层额外的处理层，将神经网络的输出变成一个概率分布
原始神经网络的输出被用作置信度来生成新的输出，而新的 输出满足概率分布的所有要求。这个新的输出可以理解为经过神经网络的推导， 一个样例 为不同类别的概率分别是多大

深层神经网络实际上有组合特征提取的功能
tf.clip_by_ value 函数可以将一个张量中的 数值限制在一个范围之内
###4.2.2自定义损失函数
##4.3神经网络损失算法
##4.4神经网络进一步优化
###4.4.1学习率的设置
###4.4.2过拟合问题
